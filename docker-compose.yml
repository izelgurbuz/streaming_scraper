version: "3.8"

services:
  # keeping track of all brokers and the leaders - Kafka (this version) needs Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      # Each heartbeat tick = 2000ms, ZooKeeper uses this to track broker health
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT

      # Tell clients (anything that connects to Kafka to produce or consume messages) where to call you:
      # - Inside Docker network, call me at kafka:9092
      # - From your laptop, call me at localhost:29092
      # When Kafka responds, it gives:
      # - The broker address that owns the topic partition.
      # - Which partition to write to or read from.
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092

      # Open your ears on these ports:
      # - 9092 for Docker friends,
      # - 29092 for outside world.
      # The initial handshake always happens here
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092

      # When brokers chat among themselves, use the internal PLAINTEXT door
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

      # Create topics automatically when a producer or consumer references them - don't try in prod
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181

  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: app
      POSTGRES_PASSWORD: app
      POSTGRES_DB: streamdb
    ports:
      - "5555:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  mongo:
    image: mongo:7
    ports:
      - "27017:27017"

  redis:
    image: redis:7
    ports:
      - "6379:6379"

  airflow-webserver:
    image: apache/airflow:2.9.3
    restart: always
    depends_on:
      - postgres
      - redis
      - airflow-scheduler
    environment:
      # The scheduler runs everything inside the same container or machine
      # It launches subprocesses (forks) directly on the host to execute tasks
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      #Airflow internally uses SQLAlchemy
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://app:app@postgres:5432/streamdb
      # Key for encrypting connections/variables (must be a valid Fernet key in prod)
      # Encrypts sensitive data (passwords, secrets) in Airflowâ€™s metadata DB - connections
      # AIRFLOW__CORE__FERNET_KEY: "32 bit keyy"
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "false"

      AIRFLOW__SMTP__SMTP_HOST: smtp.gmail.com
      AIRFLOW__SMTP__SMTP_PORT: 587
      AIRFLOW__SMTP__SMTP_STARTTLS: "True"
      AIRFLOW__SMTP__SMTP_SSL: "False"
      AIRFLOW__SMTP__SMTP_USER: ${GMAIL_USER}
      AIRFLOW__SMTP__SMTP_PASSWORD: ${GMAIL_PASS}
      AIRFLOW__SMTP__SMTP_MAIL_FROM: ${GMAIL_USER}

      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}

    volumes:
      - ./dags:/opt/airflow/dags
      - /etc/localtime:/etc/localtime:ro
    ports:
      - "8081:8080"
    command: webserver # <-- REQUIRED !!!, tells Airflow to start its webserver

  airflow-scheduler:
    image: apache/airflow:2.9.3
    restart: always
    depends_on:
      - postgres
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://app:app@postgres:5432/streamdb
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "false"

      AIRFLOW__SMTP__SMTP_HOST: smtp.gmail.com
      AIRFLOW__SMTP__SMTP_PORT: 587
      AIRFLOW__SMTP__SMTP_STARTTLS: "True"
      AIRFLOW__SMTP__SMTP_SSL: "False"
      AIRFLOW__SMTP__SMTP_USER: ${GMAIL_USER}
      AIRFLOW__SMTP__SMTP_PASSWORD: ${GMAIL_PASS}
      AIRFLOW__SMTP__SMTP_MAIL_FROM: ${GMAIL_USER}

      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}

    volumes:
      - ./dags:/opt/airflow/dags
    command: scheduler

  airflow-init:
    image: apache/airflow:2.9.3
    entrypoint: /bin/bash
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://app:app@postgres:5432/streamdb
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "false"

    command:
      - -c
      - |
        airflow db init &&
        airflow users create \
          --username admin \
          --password admin \
          --firstname Izel \
          --lastname Admin \
          --role Admin \
          --email admin@example.com
    depends_on:
      - postgres

volumes:
  postgres_data:
